% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/valiCATE.R
\name{valiCATE}
\alias{valiCATE}
\title{CATEs Validation}
\usage{
valiCATE(
  Y_tr,
  Y_val,
  D_tr,
  D_val,
  X_tr,
  X_val,
  cates_val,
  strategies = c("WR", "HT", "AIPW"),
  denoising = c("none", "cddf1", "cddf2", "mck1", "mck2", "mck3"),
  pscore_val = NULL,
  mu_val = NULL,
  mu0_val = NULL,
  mu1_val = NULL,
  n_groups = 5,
  beneficial = TRUE,
  n_boot = 200,
  crossfit_dr = TRUE,
  verbose = TRUE
)
}
\arguments{
\item{Y_tr}{Observed outcomes for the training sample.}

\item{Y_val}{Observed outcomes for the validation sample.}

\item{D_tr}{Treatment indicator for the training sample.}

\item{D_val}{Treatment indicator for the validation sample.}

\item{X_tr}{Covariate matrix for the training sample (no intercept).}

\item{X_val}{Covariate matrix for the validation sample (no intercept).}

\item{cates_val}{Named list storing CATE predictions on the validation sample produced by different models. Models must be estimated using only the training sample.}

\item{strategies}{Character vector controlling the identification and estimation strategies to implement for BLP and GATES. Admitted values are \code{"WR"}, \code{"HT"}, and \code{"AIPW"}.}

\item{denoising}{Character vector controlling if and which additional covariates to include in the regressions for BLP and GATES to reduce the variance of the estimation. Admitted values are \code{"none"}, \code{"cddf1"}, \code{"cddf2"}, \code{"mck1"}, \code{"mck2"}, and \code{"mck3"}.}

\item{pscore_val}{Propensity score predictions on the validation sample. Must be produced by a model estimated using only the training sample (unless the propensity score is known, in which case we provide the true values).}

\item{mu_val}{Conditional mean predictions on the validation sample. Must be produced by a model estimated using only the training sample.}

\item{mu0_val}{Control units' conditional mean predictions on the validation sample. Must be produced by a model estimated using only the training sample.}

\item{mu1_val}{Treated units' conditional mean predictions on the validation sample. Must be produced by a model estimated using only the training sample.}

\item{n_groups}{Number of groups to be formed for the GATES analysis.}

\item{beneficial}{Logical, whether the treatment is beneficial to units. If \code{TRUE}, units are ranked according to decreasing values of \code{cates_val} to estimate the RATEs, otherwise they are ranked according to increasing values of \code{cates_val}.}

\item{n_boot}{Number of bootstrap replications to estimate the standard error of the RATE estimates.}

\item{crossfit_dr}{Logical, whether the doubly-robust scores should be cross-fitted in the validation sample. If \code{FALSE}, the scores are constructed using the out-of-sample predictions from the nuisance models trained in the training sample.}

\item{verbose}{Logical, set to FALSE to prevent the function from printing the progresses.}
}
\value{
An \code{valiCATE} object.
}
\description{
Validates CATE models by estimating the best linear predictor (BLP) of the actual CATEs using the estimated
CATEs, the sorted group average treatment effects (GATES), and the rank-weighted average treatment effects (RATEs) induced by
the estimated CATEs.
}
\details{
The user must provide observations on the outcomes, the treatment status, and the covariates of units in the training and validation samples separately
using the first six arguments. The user must also provide a named list storing CATE predictions on the validation sample produced from different models (the Example section below shows how to construct such a list).
Be careful, CATE models must be estimated using only the training sample to achieve valid inference.\cr

The \code{\link{valiCATE}} function allows the implementation of three different strategies for BLP and GATES identification and estimation: a) Weighted Residuals (WR), Horwitz-Thompson (HT), and
Augmented Inverse-Probability Weighting (AIPW). The user can choose their preferred strategies by controlling the \code{strategies} argument. This has no impact on RATEs estimation. GATES are also
always estimated using an additional nonparametric approach.\cr

Most of the BLP and GATES estimation strategies involve fitting a suitable linear model. For each model, there exist various sets of constructed covariates that one can add to reduce the variance of
the estimation. The user can choose whether to add these additional covariates by controlling the \code{denoising} argument (check the online
\href{https://riccardo-df.github.io/valiCATE/articles/denoising.html}{denoising vignette} for details). This has no impact on RATEs estimation and on the results from the nonparametric GATES estimation strategy.

The constructed covariates depend on particular nuisance functions, e.g., propensity score and conditional mean of the outcome. The user can supply predictions on the validation sample of these functions
by using the  optional arguments \code{pscore_val}, \code{mu_val}, \code{mu0_val}, and \code{mu1_val}. Be careful, as these predictions must be produced by models fitted using only the training sample. If not
provided by the user, these functions are estimated internally via honest \code{\link[grf]{regression_forest}}s using only the training sample. \cr

For the linear models, standard errors are estimated using the Eicker-Huber-White estimator. Under our careful sample splitting procedure, these standard errors can then used to test various
hypotheses of effect heterogeneity. For the GATES, we focus on two distinct hypotheses: whether all GATES are equal to each other, and whether the largest and the smallest GATES are different from each other.
The nonparametric approach tests only the first of these hypotheses. Check the \href{https://riccardo-df.github.io/valiCATE/articles/hypotheses-testing.html}{hypotheses testing vignette}
for details.\cr

To estimate the BLP and GATES using the AIPW strategy, doubly-robust scores are estimated internally in one of two ways: if \code{crossfit_dr} is \code{TRUE}, we use
the validation sample and 5-fold cross fitting with honest regression forests (see the
\code{\link[aggTrees]{dr_scores}} function for details), while if \code{crossfit_dr} is \code{FALSE}, we use the out-of-sample predictions from the nuisance models trained
using the training sample. The doubly-robust scores are also used to estimate the RATEs.\cr

Groups for the GATES analysis are constructed by cutting the distribution of \code{cates_val} into \code{n_groups} quantiles. If this leads to one or more groups composed of only treated or only control units,
the function raises an error. Possible solutions include: a) change your original training-validation sample split; b) increase the fraction of observations allocated to the validation sample.\cr

The \code{\link{valiCATE}} function estimates two different RATEs: AUTOC and QINI coefficients. Sample-averaging estimators are employed. Standard errors are estimated by the standard deviation of the bootstrap
estimates obtained using the half-sample bootstrap.\cr

Check the online \href{https://riccardo-df.github.io/valiCATE/articles/valiCATE-short-tutorial.html}{short tutorial} for a guided usage of this function.\cr
}
\examples{
\donttest{## Generate data.
set.seed(1986)

n <- 1000
k <- 2

X <- matrix(rnorm(n * k), ncol = k)
colnames(X) <- paste0("x", seq_len(k))
D <- rbinom(n, size = 1, prob = 0.4)
mu0 <- 0.5 * X[, 1]
mu1 <- 0.5 * X[, 1] + X[, 2]
Y <- mu0 + D * (mu1 - mu0) + rnorm(n)

## Sample split.
train_idx <- sample(c(TRUE, FALSE), length(Y), replace = TRUE)

X_tr <- X[train_idx, ]
X_val <- X[!train_idx, ]

D_tr <- D[train_idx]
D_val <- D[!train_idx]

Y_tr <- Y[train_idx]
Y_val <- Y[!train_idx]

## CATEs estimation. Models are estimated with training sample.
# T-learner.
library(grf)

forest_treated <- regression_forest(X_tr[D_tr == 1, ], Y_tr[D_tr == 1])
forest_control <- regression_forest(X_tr[D_tr == 0, ], Y_tr[D_tr == 0])
cates_val_t <- predict(forest_treated, X_val)$predictions - 
               predict(forest_control, X_val)$predictions 

# Grf.
forest_grf <- causal_forest(X_tr, Y_tr, D_tr) 
cates_val_grf <- predict(forest_grf, X_val)$predictions 

## CATEs validation. 
# Use all strategies with no denoising.
strategies <- c("WR", "HT")
denoising <- "none"

# We know true pscore.
pscore_val <- rep(0.4, length(Y_val))

# Construct CATEs list.
cates_val <- list("T-learner" = cates_val_t,
                  "grf" = cates_val_grf)

# Call main function.
validation <- valiCATE(Y_tr, Y_val, D_tr, D_val, X_tr, X_val, cates_val, 
                        strategies = strategies, denoising = denoising, 
                        pscore_val = pscore_val)

## Generic S3 methods.
summary(validation, target = "BLP")
summary(validation, target = "BLP", latex = TRUE)

summary(validation, target = "GATES")
summary(validation, target = "GATES", latex = TRUE)

summary(validation, target = "RATE")
summary(validation, target = "RATE", latex = TRUE)

plot(validation, target = "GATES")
plot(validation, target = "TOC")
plot(validation, target = "RATE")}

}
\author{
Riccardo Di Francesco
}
